{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.io import savemat # for saving data to .mat file\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to functions\n",
    "sys.path.append(r\"/home/illich/SeriesDistance/SeriesDistance Python NEU/functions Python NEU/\")\n",
    "\n",
    "# import functions\n",
    "from f_smooth_DP import f_smooth_DP\n",
    "from f_ReplaceEqualNeighbours import f_ReplaceEqualNeighbours\n",
    "from f_FindSplitPoints import f_FindSplitPoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2JInput data SD_Analysis_Continuous:\n",
      "type obs:  <class 'numpy.ndarray'>\n",
      "dtype obs:  float64\n",
      "shape obs:  (10000,)\n",
      "\n",
      "\n",
      "type sim:  <class 'numpy.ndarray'>\n",
      "dtype sim:  float64\n",
      "shape sim:  (10000,)\n",
      "\n",
      "\n",
      "orginal obs: var: 69.171188618656, # extremes: 1990, diff(obs)=3408.547\n",
      "orginal sim: var: 52.86143165392219, # extremes: 500, diff(sim)=2680.4173\n",
      "\n",
      "\n",
      "input data for f_dp1d:\n",
      "type xy:  <class 'numpy.ndarray'>\n",
      "dtype xy:  float64\n",
      "shape xy:  (10000, 2)\n",
      "\n",
      "\n",
      "output data for f_dp1d:\n",
      "type xy_dp:  <class 'numpy.ndarray'>\n",
      "dtype xy_dp:  float64\n",
      "shape xy_dp:  (500, 2)\n",
      "\n",
      "\n",
      "smoothed obs: var: 69.03954912923022, # extremes: 246, diff(obs)=2957.607\n",
      "smoothed sim: var: 52.86143165392219, # extremes: 500, diff(sim)=2680.4173\n",
      "\n",
      "\n",
      "Data after smoothening:\n",
      "type obs:  <class 'numpy.ndarray'>\n",
      "dtype obs:  float64\n",
      "shape obs:  (10000,)\n",
      "\n",
      "\n",
      "type sim:  <class 'numpy.ndarray'>\n",
      "dtype sim:  float64\n",
      "shape sim:  (10000,)\n",
      "\n",
      "\n",
      "Data after f_replace_equal_neighbours:\n",
      "type obs:  <class 'numpy.ndarray'>\n",
      "dtype obs:  float64\n",
      "shape obs:  (10000,)\n",
      "\n",
      "\n",
      "type sim:  <class 'numpy.ndarray'>\n",
      "dtype sim:  float64\n",
      "shape sim:  (10000,)\n",
      "\n",
      "\n",
      "timeseries_splits:  [0, np.int64(241), np.int64(538), np.int64(783), np.int64(986), np.int64(1288), np.int64(1531), np.int64(1788), np.int64(2002), np.int64(2212), np.int64(2538), np.int64(2788), np.int64(3256), np.int64(3494), np.int64(3752), np.int64(4020), np.int64(4212), np.int64(4524), np.int64(4787), np.int64(5003), np.int64(5219), np.int64(5485), np.int64(5788), np.int64(6029), np.int64(6288), np.int64(6522), np.int64(6735), np.int64(7038), np.int64(7256), np.int64(7508), np.int64(7788), np.int64(8038), np.int64(8538), np.int64(8788), np.int64(9038), np.int64(9215), np.int64(9482), 9999]\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "STOP SD_Analysis_Continuous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 142\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeseries_splits: \u001b[39m\u001b[38;5;124m'\u001b[39m, timeseries_splits)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 142\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTOP SD_Analysis_Continuous\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# plot input data\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pf_input:\n",
      "\u001b[0;31mException\u001b[0m: STOP SD_Analysis_Continuous"
     ]
    }
   ],
   "source": [
    "#  ====================================================================== \n",
    "#                 Series Distance Analysis (Continuous Mode) \n",
    "#  ======================================================================\n",
    "#  last modification 16.08.2016\n",
    "\n",
    "# This development release of the SeriesDistance (SD) method is applicable to continuous \n",
    "# observed (obs) and simulated (sim) discharge time series. It outputs a 2d-error \n",
    "# distribution for the entire time series. Contrary to the event based method the \n",
    "# continuous version does not differentiate periods of low-flow from periods of events.  \n",
    "# Nevertheless, the entire hydrograph is classified into rising and falling limbs. The \n",
    "# interpretation of these classes is however only meaningful if the periods of low-flow \n",
    "# do not cover a significant portion of the hydrograph. Note: For plotting,\n",
    "# the error distributions for rise and fall are combined.\n",
    "\n",
    "# Further information:\n",
    "# Seibert, S. P., Ehret, U., and Zehe, E., 2016: Disentangling timing and amplitude errors in streamflow simulations, Hydrol. Earth Syst. Sci.\n",
    "# Ehret, U., Zehe, E., 2011. Series distance - An intuitive metric to quantify hydrograph similarity in terms of occurrence, amplitude and timing of hydrological events. Hydrol. Earth Syst. Sci. 15, 877â€“896. doi:10.5194/hess-15-877-2011\n",
    "\n",
    "# Dependencies\n",
    "# All required functions are stored in folder \\functions\n",
    "\n",
    "# Input (ascii format)\n",
    "#  - obs: [n,1] matrix with equidistant and NaN-free time series of observed discharge data.\n",
    "#  - sim: [n,1] matrix with equidistant and NaN-free time series of simulated discharge data. \n",
    "#  - timeseries_splits: [n,1] optional matrix with points in time where the 'obs' and 'sim' time series will be split to increase computational speed.\n",
    "#     It must include the first and the last timestep of 'obs' and 'sim'. E.g. if 'obs' and 'sim' are [1100,1],\n",
    "#     then 'timeseries_splits' could be (1, 250, 800, 1100)\n",
    "\n",
    "# Parameters are explained and specified in the parameter block\n",
    "\n",
    "# Outputs (all stored within a single binary file .mat)\n",
    "#  - obs:              observed discharge (smoothed)\n",
    "#  - sim:              simulated discharge\n",
    "#  - segs_obs_opt_all: optimized segments in obs\n",
    "#  - segs_sim_opt_all: optimized segments in sim\n",
    "#  - connectors:       SD connectors\n",
    "#  - e_sd_q_all:       SD magnitude errors for entire time series\n",
    "#  - e_sd_t_all:       SD timing errors for entire time series\n",
    "#  - parameters:       all parameters, i.e. error_model, objective function weights, smoothing parameters,  \n",
    "#                       are included in the outputfile\n",
    "\n",
    "# Start from scratch\n",
    "os.system('clear')  # for Linux and macOS\n",
    "# os.system('cls')  # for Windows\n",
    "plt.close('all')  # close all figures\n",
    "\n",
    "# specify paths and parameters, read inputs\n",
    "# os.chdir('ADD_YOUR_PATH_HERE')  # set working directory\n",
    "\n",
    "########################################################### mein Working Directory ###########################################################\n",
    "os.chdir(r\"/home/illich/SeriesDistance/\")\n",
    "########################################################### mein Working Directory ###########################################################\n",
    "\n",
    "# read input\n",
    "obs = np.genfromtxt('data/HOST_timeseries.csv', delimiter=';', skip_header=1, usecols=2, max_rows=10000)\n",
    "sim = np.genfromtxt('data/HOST_timeseries.csv', delimiter=';', skip_header=1, usecols=3, max_rows=10000)\n",
    "\n",
    "# print some information\n",
    "print('Input data SD_Analysis_Continuous:')\n",
    "# print(\"obs: \", obs)\n",
    "print('type obs: ', type(obs))\n",
    "print('dtype obs: ', obs.dtype)\n",
    "print('shape obs: ', obs.shape)\n",
    "print('\\n')\n",
    "# print(\"sim: \", sim)\n",
    "print('type sim: ', type(sim))\n",
    "print('dtype sim: ', sim.dtype)\n",
    "print('shape sim: ', sim.shape)\n",
    "print('\\n')\n",
    "\n",
    "# output filenames\n",
    "outfile = './results/output.mat'\n",
    "\n",
    "# smoothing options\n",
    "smooth_flag = True         # smooth both obs and sim (default=True)\n",
    "nse_smooth_limit = 0.99    # specifies degree of smoothing according to NSE criterion (default=0.99)\n",
    "\n",
    "# specification of the magnitude error model\n",
    "error_model = 'relative'  # 'relative' or 'standard'; (default='relative')\n",
    "\n",
    "# options for time series splitting:\n",
    "timeseries_split_by_user = False  # 'true': time series splits provided by user in ascii file. 'false': splits will be placed by the program (default=False)\n",
    "split_frequency = 250             # only required if timeseries_split_by_user=False: this is the default distance between 2 splits (default=500)\n",
    "\n",
    "# parametrization of the objective function \n",
    "weight_nfc = 1/7   # weights number of re-assigned hydrological cases (default= 1)    \n",
    "weight_rds = 1/7   # weights the importance of the re-assigned segments (default=1) \n",
    "weight_sdt = 5/7   # weights the SD timing error component (default=5)\n",
    "weight_sdv = 0     # weights the SD magnitude error component (default=0)\n",
    "\n",
    "# set plot flags \n",
    "pf_input = True                   # plots input time series ('obs' and 'sim')\n",
    "pf_segs_cons_entireTS = True      # plots obs, sim, colour-coded pairs of matching segments, SeriesDistance connectors for the entire time series\n",
    "pf_errordist = True               # plots SeriesDistance error distributions \n",
    "\n",
    "# Data manipulations and pre-processing\n",
    "\n",
    "# smooth if required (default=True)\n",
    "if smooth_flag:\n",
    "    obs_org = obs.copy()\n",
    "    sim_org = sim.copy()\n",
    "    obs, sim = f_smooth_DP(obs, sim, nse_smooth_limit)\n",
    "\n",
    "# print some information\n",
    "print('\\n')\n",
    "print('Data after smoothening:')\n",
    "# print(\"obs: \", obs)\n",
    "print('type obs: ', type(obs))\n",
    "print('dtype obs: ', obs.dtype)\n",
    "print('shape obs: ', obs.shape)\n",
    "print('\\n')\n",
    "# print(\"sim: \", sim)\n",
    "print('type sim: ', type(sim))\n",
    "print('dtype sim: ', sim.dtype)\n",
    "print('shape sim: ', sim.shape)\n",
    "print('\\n')\n",
    "\n",
    "# replace identical neighbouring values to avoid problems with assignment of unique peaks and valleys\n",
    "obs = f_ReplaceEqualNeighbours(obs)\n",
    "sim = f_ReplaceEqualNeighbours(sim)\n",
    "\n",
    "# print some information\n",
    "print('Data after f_replace_equal_neighbours:')\n",
    "# print(\"obs: \", obs)\n",
    "print('type obs: ', type(obs))\n",
    "print('dtype obs: ', obs.dtype)\n",
    "print('shape obs: ', obs.shape)\n",
    "print('\\n')\n",
    "# print(\"sim: \", sim)\n",
    "print('type sim: ', type(sim))\n",
    "print('dtype sim: ', sim.dtype)\n",
    "print('shape sim: ', sim.shape)\n",
    "print('\\n')\n",
    "\n",
    "# Define time series split points to improve coarse-graining performance\n",
    "if not timeseries_split_by_user:\n",
    "    timeseries_splits = f_FindSplitPoints(obs, sim, split_frequency)  # find split points if they are not provided by the user       \n",
    "else:\n",
    "    timeseries_splits = np.genfromtxt('data/HOST_ts_splits.csv', delimiter=';')  # read splits defined by user.\n",
    "print('timeseries_splits: ', timeseries_splits)\n",
    "print('\\n')\n",
    "\n",
    "raise Exception(\"STOP SD_Analysis_Continuous\")\n",
    "\n",
    "# plot input data\n",
    "if pf_input:\n",
    "    f_PlotInput([], obs, [], [], sim, [], [], timeseries_splits)  # show time series splits\n",
    "\n",
    "# cleanup\n",
    "del smooth_flag, nse_smooth_limit, pf_input, timeseries_split_by_user, split_frequency\n",
    "\n",
    "# Apply coarse-graining and the SD method to the entire time series \n",
    "# note: contrary to the event based method both, the coarse-graining and the SD calculation \n",
    "# take place in the same function here due to the splitting of the time series. To this end \n",
    "# the splitting is solved in a simplistic way and does not support separating the \n",
    "# coarse-graining and SD calculation as in the event-based version.\n",
    "\n",
    "# apply coarse graining and SD calculation: determines optimal level of segment aggregation for entire time series and applies SD to it\n",
    "segs_obs_opt_all, segs_sim_opt_all, connectors, e_sd_t_all, e_sd_q_all = f_CoarseGraining_SD_Continuous(\n",
    "    obs, sim, timeseries_splits, weight_nfc, weight_rds, weight_sdt, weight_sdv, error_model)\n",
    "\n",
    "# plot time series with optimized segments and connectors in an own figure\n",
    "if pf_segs_cons_entireTS:\n",
    "    f_PlotConnectedSeries(obs, segs_obs_opt_all, sim, segs_sim_opt_all, connectors)\n",
    "\n",
    "# plot 2d-error distributions\n",
    "if pf_errordist:\n",
    "    f_PlotSDErrors_OnePanel(e_sd_t_all, e_sd_q_all)\n",
    "\n",
    "# save output\n",
    "savemat(outfile, {\n",
    "    'obs': obs,\n",
    "    'sim': sim,\n",
    "    'segs_obs_opt_all': segs_obs_opt_all,\n",
    "    'segs_sim_opt_all': segs_sim_opt_all,\n",
    "    'connectors': connectors,\n",
    "    'e_sd_t_all': e_sd_t_all,\n",
    "    'e_sd_q_all': e_sd_q_all,\n",
    "    'weight_nfc': weight_nfc,\n",
    "    'weight_rds': weight_rds,\n",
    "    'weight_sdt': weight_sdt,\n",
    "    'weight_sdv': weight_sdv,\n",
    "    'error_model': error_model\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SeriesDistance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
